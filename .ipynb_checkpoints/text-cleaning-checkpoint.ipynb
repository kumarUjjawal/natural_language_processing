{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('sherlock.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg'\n"
     ]
    }
   ],
   "source": [
    "print(text[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character in the file:  581888\n"
     ]
    }
   ],
   "source": [
    "print('Character in the file: ',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File type:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('File type: ',type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '£', '½', 'à', 'â', 'æ', 'è', 'é', 'œ', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "Number of unique characters:  99\n"
     ]
    }
   ],
   "source": [
    "unique_chars = list(set(text))\n",
    "unique_chars.sort()\n",
    "print(unique_chars)\n",
    "print('Number of unique characters: ', len(unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tekenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107603\n"
     ]
    }
   ],
   "source": [
    "# split by whitespace\n",
    "words = text.split()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anonymous', 'Project', 'Gutenberg', 'volunteer', 'and', 'Jose', 'Menendez', 'cover', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Arthur', 'Conan', 'Doyle', 'Contents', 'I.', 'A', 'Scandal', 'in', 'Bohemia', 'II.', 'The', 'Red-Headed', 'League', 'III.', 'A', 'Case', 'of', 'Identity', 'IV.', 'The', 'Boscombe', 'Valley', 'Mystery', 'V.', 'The', 'Five', 'Orange', 'Pips', 'VI.', 'The', 'Man', 'with', 'the', 'Twisted', 'Lip', 'VII.', 'The', 'Adventure', 'of', 'the', 'Blue', 'Carbuncle', 'VIII.', 'The', 'Adventure', 'of', 'the', 'Speckled', 'Band', 'IX.', 'The', 'Adventure', 'of', 'the', 'Engineer’s', 'Thumb', 'X.', 'The', 'Adventure', 'of', 'the', 'Noble', 'Bachelor', 'XI.', 'The', 'Adventure']\n"
     ]
    }
   ],
   "source": [
    "print(words[100:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109228 107603\n"
     ]
    }
   ],
   "source": [
    "# split by word extraction\n",
    "import re\n",
    "\n",
    "words_alphanum = re.split('\\W+', text)\n",
    "print(len(words_alphanum), len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Produced', 'by', 'an', 'anonymous', 'Project', 'Gutenberg', 'volunteer', 'and', 'Jose', 'Menendez', 'cover', 'The', 'Adventures', 'of', 'Sherlock', 'Holmes', 'by', 'Arthur', 'Conan', 'Doyle', 'Contents', 'I', 'A', 'Scandal', 'in', 'Bohemia', 'II', 'The', 'Red', 'Headed', 'League', 'III', 'A', 'Case', 'of', 'Identity', 'IV', 'The', 'Boscombe', 'Valley', 'Mystery', 'V', 'The', 'Five', 'Orange', 'Pips', 'VI', 'The', 'Man', 'with', 'the', 'Twisted', 'Lip', 'VII', 'The', 'Adventure', 'of', 'the', 'Blue', 'Carbuncle', 'VIII', 'The', 'Adventure', 'of', 'the', 'Speckled', 'Band', 'IX', 'The', 'Adventure', 'of', 'the', 'Engineer', 's', 'Thumb', 'X', 'The', 'Adventure', 'of', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(words_alphanum[100:180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, ,, 2019, \n",
      "\n",
      ", Language, :, English, \n",
      "\n",
      ", Character, set, encoding, :, UTF-8, \n",
      "\n",
      ", *, *, *, START, OF, THIS, PROJECT, GUTENBERG, EBOOK, THE, ADVENTURES, OF, SHERLOCK, HOLMES, *, *, *, \n",
      "\n",
      "\n",
      "\n",
      ", Produced, by, an, anonymous, Project, Gutenberg, volunteer, and, Jose, Menendez, \n",
      "\n",
      "\n",
      "\n",
      ", cover, \n",
      "\n",
      "\n",
      "\n",
      ", The, Adventures, of, Sherlock, Holmes, \n",
      "\n",
      "\n",
      "\n",
      ", by, Arthur, Conan, Doyle, \n",
      "\n",
      "\n",
      "\n",
      ", Contents, \n",
      "\n",
      "\n",
      "   , I.,     , A, Scandal, in, Bohemia, \n",
      "   , II, .,    , The, Red, -, Headed, League, \n",
      "   , III, .,   , A, Case, of]\n"
     ]
    }
   ],
   "source": [
    "print(list(doc)[100:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[“How many?, I don’t know.”\n",
      "\n",
      ", “Quite so!, You have not observed., And yet you have seen., That is just\n",
      "my point., Now, I know that there are seventeen steps, because I have\n",
      "both seen and observed., By the way, since you are interested in these\n",
      "little problems, and since you are good enough to chronicle one or two\n",
      "of my trifling experiences, you may be interested in this.”, He threw\n",
      "over a sheet of thick, pink-tinted notepaper which had been lying open\n",
      "upon the table., “It came by the last post,” said he.]\n"
     ]
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "print(sentences[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(anyone, True, False),\n",
       " (anywhere, True, False),\n",
       " (at, True, False),\n",
       " (no, True, False),\n",
       " (cost, False, False),\n",
       " (and, True, False),\n",
       " (with, True, False),\n",
       " (, False, False),\n",
       " (almos, False, False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_example = text[109:150]\n",
    "\n",
    "[(token, token.is_stop, token.is_punct) for token in nlp(sent_example)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lower = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lower = nlp(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿ False\n",
      "\n",
      " False\n",
      "project False\n",
      "gutenberg False\n",
      "'s True\n",
      "the True\n",
      "adventures False\n",
      "of True\n",
      "sherlock False\n",
      "holmes False\n"
     ]
    }
   ],
   "source": [
    "for token in doc_lower[:10]:\n",
    "    print(token, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of stop words in spacy:  326\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(\"Dictionary of stop words in spacy: \", len(list(STOP_WORDS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(e, 'e', 1720370409040345145, 'X'),\n",
       " (use, 'use', 6873750497785110593, 'NOUN'),\n",
       " (of, 'of', 886050111519832510, 'ADP'),\n",
       " (anyone, 'anyone', 444920330522528470, 'PRON'),\n",
       " (anywhere, 'anywhere', 5899329028063008718, 'ADV'),\n",
       " (at, 'at', 11667289587015813222, 'ADP'),\n",
       " (no, 'no', 13055779130471031426, 'INTJ')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_sent = text[100:130]\n",
    "\n",
    "[(token, token.lemma_, token.lemma, token.pos_) for token in nlp(lemma_sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
